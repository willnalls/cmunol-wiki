version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:88.0) Gecko/20100101 Firefox/88.0
author=AlbertL
charset=UTF-8
csum=
ctime=1620439431
host=67.163.151.95
name=GradebookArticles.SignLanguageSynthesis
rev=1
targets=
text=:Category: Varia%0a:Essential: {Category.Varia$:essential}%0a:Title: Sign Language Synthesis%0a:Author: AlbertL%0a:Section: A%0a:Completed: 07.05.2021 - 19:03%0a:Status: ungraded%0a%0a(:foxform Site.FoxForms#gradeitem:)%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a----%0a%0a%0a%25blue%25 '''Grading History'''%0a%0a[[#history]]%0a%0a[[#historyend]]%0a%0a%25blue%25 '''Comments for student'''%0a%0a[[#comments]]%0a%0a[[#commentsend]]%0a%0a----%0a----%0a!!%0a%0aSummary: \\%0a%0a[[#summary]]%0a%0aDifferent efforts to automatically generate sign language.%0a%0a[[#summaryends]]%0a%0a----%0a[[#content]]%0a%0aAs documented in other articles, there have been plenty of efforts to produce believable speech from text and other sources. However there have also been significant efforts to automatically produce sign language. In many ways this is a similar problem to speech synthesis but instead of transforming phonetic symbols to an audio wave (with all its complicated interactions), the text is transformed/translated into body movements which have to be smoothly animated. As an example of actual working results, the Microsoft translator API has partnered with ProDeaf to produce cartoon results like this.%0ahttps://www.youtube.com/watch?v=fEvvrLpTb0E%0aIn recent years we have also seen the rise of photo-realistic video production and good translation using neural networks. In this paper https://link.springer.com/article/10.1007/s11263-019-01281-2 it seems the authors applied these advances to produce believable videos of sign language, directly producing the video rather than animating a cartoon figure.%0a%0a[[#contentends]]%0a----
time=1620439431
author:1620439431=AlbertL
diff:1620439431:1620439431:=1,47d0%0a%3c :Category: Varia%0a%3c :Essential: {Category.Varia$:essential}%0a%3c :Title: Sign Language Synthesis%0a%3c :Author: AlbertL%0a%3c :Section: A%0a%3c :Completed: 07.05.2021 - 19:03%0a%3c :Status: ungraded%0a%3c %0a%3c (:foxform Site.FoxForms#gradeitem:)%0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c ----%0a%3c %0a%3c %0a%3c %25blue%25 '''Grading History'''%0a%3c %0a%3c [[#history]]%0a%3c %0a%3c [[#historyend]]%0a%3c %0a%3c %25blue%25 '''Comments for student'''%0a%3c %0a%3c [[#comments]]%0a%3c %0a%3c [[#commentsend]]%0a%3c %0a%3c ----%0a%3c ----%0a%3c !!%0a%3c %0a%3c Summary: \\%0a%3c %0a%3c [[#summary]]%0a%3c %0a%3c Different efforts to automatically generate sign language.%0a%3c %0a%3c [[#summaryends]]%0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c As documented in other articles, there have been plenty of efforts to produce believable speech from text and other sources. However there have also been significant efforts to automatically produce sign language. In many ways this is a similar problem to speech synthesis but instead of transforming phonetic symbols to an audio wave (with all its complicated interactions), the text is transformed/translated into body movements which have to be smoothly animated. As an example of actual working results, the Microsoft translator API has partnered with ProDeaf to produce cartoon results like this.%0a%3c https://www.youtube.com/watch?v=fEvvrLpTb0E%0a%3c In recent years we have also seen the rise of photo-realistic video production and good translation using neural networks. In this paper https://link.springer.com/article/10.1007/s11263-019-01281-2 it seems the authors applied these advances to produce believable videos of sign language, directly producing the video rather than animating a cartoon figure.%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a\ No newline at end of file%0a
host:1620439431=67.163.151.95
