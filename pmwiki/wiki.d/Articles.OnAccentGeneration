version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36
author=EthanW
charset=UTF-8
csum=
ctime=1618188452
host=58.247.22.142
name=Articles.OnAccentGeneration
rev=2
targets=GradebookArticles.OnAccentGeneration,Articles.OnAccentGeneration,Category.Varia
text=(:if authgroup @tas:)%0a%0a(:toggle id=gi show="show grading interface" hide="hide grading interface":)%0a%0a>>id=gi%3c%3c%0a%0a[[GradebookArticles.{$Name}|See article in gradebook]] \\%0a[[{$FullName}?action=diff|See all changes to article]]%0a%0a(:foxform Site.FoxForms#gradeitem:)%0a%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a>>%3c%3c%0a%0a----%0a%0a(:ifend:)%0a%0a[[!Varia]]%0a%0a!On Accent Generation%0a%0a:Author: aryans%0a%0a'''Summary:''' \\%0a%0a[[#summary]]%0a%0aSummary of a statistical method by which a model can generate non-SA English words from SA English words%0a%0a[[#summaryends]]%0a%0a----%0a[[#content]]%0a%0aAs voice-recognition systems grow more and more ubiquitous, artificial intelligence researchers are faced with the challenge of having their systems recognize a progressively wider variety of accents. On a personal note, my parents have Indian accents that are perfectly intelligible for the average American person but often completely confuse Siri, which works best with Standard American (SA) English. Like in many areas of AI research, one of the limiting factors for the progression of recognition of non-SA English is a lack of data for many accents. Below, I present a summary of a project by researchers at Moscow Institute for Physics and Technology that seeks to make the construction of these datasets much easier. %0a%0aThe model is trained on the George Mason University dataset which gave us the "go meet her Wednesday", "a snack for her brother Bob", and "fresh snow peas" soundbites. First, the manually-generated transcriptions of the soundbites are reduced from 169 IPA sounds to the 39 sounds present in the CMU Pronouncing Dictionary, which contains over 100000 words. Then, the important differences from SAE (those that determine phonological rules for accents) for each word of each GMU soundbite are fetched, for both the original and reduced versions of these soundbites. Then, the model learns the phonological rules for each accent based on these differences. For the non-reduced version, the model was able to learn all twenty of the phonological rules given by GMU. In the reduced case, since information was lost in going from 169 to 39 sounds, the model could only learn thirteen of the twenty rules. %0a%0aThe goal of this is to create a transformation from the non-SA English to SA English, so that can be fed to a voice-recognition algorithm which likely trained on SA English data. However, models trained on the GMU dataset usually overfit to the specific input of that dataset. However, using this model, the researchers seek to create another dataset using the CMU Pronunciation Dictionary that has many accented words, rather than just the ones in the GMU dataset. By modifying the SA English words in the CMU dataset to sound like Russian accented words, the researchers were able to train a model that recognized Russian-accented words with 59 percent accuracy. %0a%0aSource: Fedor Kitashov, Elizaveta Svitanko, and Debojyoti Dutta. "Foreign English Accent Adjustment by Learning Phonetic Patterns" (2018)%0a%0a[[#contentends]]%0a----%0a----%0a%0a!!Expansions:%0a[[#expansions]]%0a#foxbegin 210430-071911-754990#%0a(:div1 class=expansionhead:)%0a!!!Simulate accented data %0a-> - EthanW%0a(:div1end:) %0a>>messageitem%3c%3c %0aOne challange in training a more intelligent model to recognize accented speech is the lack of data, which easily leads to overfitting. Data augmentation, as you mentioned in the last paragraph, could be of help. %0a%0aRecall that voice onset time (VOT) and fundamental frequency (F0) are two important acoustics parameters. I once envolved in a study where researchers manipulated VOT and FO of "b" and "p" to different degrees. The result shows that it influenced how listeners classified the manually accented audio as "beer" or "pier". Hypothetically, similar techniques can be applied to generate more accented data from the non-accented ones. %0a>>%3c%3c%0a#foxend 210430-071911-754990#%0a[[#expansionsend]]%0a%0a----%0a%25red%25 '''Add an expansion:'''%0a%0a(:if [ exists GradebookExpansions.{$Name}-{$Author} || equal {$Author} {$:Author} ] :)%0a%0a(:else:)%0a%0a(:foxform Site.FoxForms#newexpansion:)%0a%0a(:ifend:)%0a%0a----%0a----%0a%0a!!Comments%0a%0a%0a%0a(:section: B:)%0a(:Category: Varia:)
time=1619767151
author:1619767151=EthanW
diff:1619767151:1618188452:=51,61c51%0a%3c #foxbegin 210430-071911-754990#%0a%3c (:div1 class=expansionhead:)%0a%3c !!!Simulate accented data %0a%3c -> - EthanW%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c One challange in training a more intelligent model to recognize accented speech is the lack of data, which easily leads to overfitting. Data augmentation, as you mentioned in the last paragraph, could be of help. %0a%3c %0a%3c Recall that voice onset time (VOT) and fundamental frequency (F0) are two important acoustics parameters. I once envolved in a study where researchers manipulated VOT and FO of "b" and "p" to different degrees. The result shows that it influenced how listeners classified the manually accented audio as "beer" or "pier". Hypothetically, similar techniques can be applied to generate more accented data from the non-accented ones. %0a%3c >>%3c%3c%0a%3c #foxend 210430-071911-754990#%0a---%0a> %0a
host:1619767151=58.247.22.142
author:1618188452=aryans
diff:1618188452:1618188452:=1,73d0%0a%3c (:if authgroup @tas:)%0a%3c %0a%3c (:toggle id=gi show="show grading interface" hide="hide grading interface":)%0a%3c %0a%3c >>id=gi%3c%3c%0a%3c %0a%3c [[GradebookArticles.{$Name}|See article in gradebook]] \\%0a%3c [[{$FullName}?action=diff|See all changes to article]]%0a%3c %0a%3c (:foxform Site.FoxForms#gradeitem:)%0a%3c %0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c >>%3c%3c%0a%3c %0a%3c ----%0a%3c %0a%3c (:ifend:)%0a%3c %0a%3c [[!Varia]]%0a%3c %0a%3c !On Accent Generation%0a%3c %0a%3c :Author: aryans%0a%3c %0a%3c '''Summary:''' \\%0a%3c %0a%3c [[#summary]]%0a%3c %0a%3c Summary of a statistical method by which a model can generate non-SA English words from SA English words%0a%3c %0a%3c [[#summaryends]]%0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c As voice-recognition systems grow more and more ubiquitous, artificial intelligence researchers are faced with the challenge of having their systems recognize a progressively wider variety of accents. On a personal note, my parents have Indian accents that are perfectly intelligible for the average American person but often completely confuse Siri, which works best with Standard American (SA) English. Like in many areas of AI research, one of the limiting factors for the progression of recognition of non-SA English is a lack of data for many accents. Below, I present a summary of a project by researchers at Moscow Institute for Physics and Technology that seeks to make the construction of these datasets much easier. %0a%3c %0a%3c The model is trained on the George Mason University dataset which gave us the "go meet her Wednesday", "a snack for her brother Bob", and "fresh snow peas" soundbites. First, the manually-generated transcriptions of the soundbites are reduced from 169 IPA sounds to the 39 sounds present in the CMU Pronouncing Dictionary, which contains over 100000 words. Then, the important differences from SAE (those that determine phonological rules for accents) for each word of each GMU soundbite are fetched, for both the original and reduced versions of these soundbites. Then, the model learns the phonological rules for each accent based on these differences. For the non-reduced version, the model was able to learn all twenty of the phonological rules given by GMU. In the reduced case, since information was lost in going from 169 to 39 sounds, the model could only learn thirteen of the twenty rules. %0a%3c %0a%3c The goal of this is to create a transformation from the non-SA English to SA English, so that can be fed to a voice-recognition algorithm which likely trained on SA English data. However, models trained on the GMU dataset usually overfit to the specific input of that dataset. However, using this model, the researchers seek to create another dataset using the CMU Pronunciation Dictionary that has many accented words, rather than just the ones in the GMU dataset. By modifying the SA English words in the CMU dataset to sound like Russian accented words, the researchers were able to train a model that recognized Russian-accented words with 59 percent accuracy. %0a%3c %0a%3c Source: Fedor Kitashov, Elizaveta Svitanko, and Debojyoti Dutta. "Foreign English Accent Adjustment by Learning Phonetic Patterns" (2018)%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a%3c ----%0a%3c %0a%3c !!Expansions:%0a%3c [[#expansions]]%0a%3c %0a%3c [[#expansionsend]]%0a%3c %0a%3c ----%0a%3c %25red%25 '''Add an expansion:'''%0a%3c %0a%3c (:if [ exists GradebookExpansions.{$Name}-{$Author} || equal {$Author} {$:Author} ] :)%0a%3c %0a%3c (:else:)%0a%3c %0a%3c (:foxform Site.FoxForms#newexpansion:)%0a%3c %0a%3c (:ifend:)%0a%3c %0a%3c ----%0a%3c ----%0a%3c %0a%3c !!Comments%0a%3c %0a%3c %0a%3c %0a%3c (:section: B:)%0a%3c (:Category: Varia:)%0a\ No newline at end of file%0a
host:1618188452=184.190.142.79
