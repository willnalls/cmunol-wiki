version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36
author=saumyaB
charset=UTF-8
csum=
ctime=1620419802
host=128.237.82.1
name=Articles.SearlesChineseRoomArgument
rev=3
targets=GradebookArticles.SearlesChineseRoomArgument,Articles.SearlesChineseRoomArgument,Category.Varia
text=(:if authgroup @tas:)%0a%0a(:toggle id=gi show="show grading interface" hide="hide grading interface":)%0a%0a>>id=gi%3c%3c%0a%0a[[GradebookArticles.{$Name}|See article in gradebook]] \\%0a[[{$FullName}?action=diff|See all changes to article]]%0a%0a(:foxform Site.FoxForms#gradeitem:)%0a%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a>>%3c%3c%0a%0a----%0a%0a(:ifend:)%0a%0a[[!Varia]]%0a%0a!Searles Chinese Room Argument%0a%0a:Author: jjmonroe%0a%0a'''Summary:''' \\%0a%0a[[#summary]]%0a%0aAn exploration of the difference between "understanding" language and manipulating symbols%0a%0a[[#summaryends]]%0a%0a----%0a[[#content]]%0a%0aOne of the major philosophical arguments against computers being able to think in the way that humans do (and by extension against the use of the Turing test as a measure of artificial intelligence), introduced in 1980 by John Searle, has its roots in linguistics as a measure for understanding. The argument, commonly referred to as "the Chinese Room" argument, imagines a person who speaks and understands only English being trapped in a room where he has a manual of instructions on how to operate on Chinese language documents. Following the manual, the man takes in pages of Chinese characters slipped under the door, performs the specified operations based on them, and slips the reply back out under the door. To the person on the outside (analogous to the one performing the Turing test), it would appear that the person inside is reading their messages and replying based on the content. In actuality, the person inside is doing pure symbol manipulation: moving around letters, instead of processing words. The conclusion of this argument is that because the person following the program in the room can feasibly reply in a language they do not understand, formulating coherent responses by pure symbol manipulation, an AI formulating a coherent reply is not sufficient to demonstrate true understanding.%0a%0aThis ties in to the Pragmatics section of our course. In the same way there could be a program that follows all the morphological or syntactic rules of a language, there could conceivably be one that follows the rules of content as well, creating well-formed responses without ever touching on the content of the words or sentences.%0a%0aSource:%0ahttps://plato.stanford.edu/entries/chinese-room/#ChinRoomArgu%0a%0a[[#contentends]]%0a----%0a----%0a%0a!!Expansions:%0a[[#expansions]]%0a#foxbegin 210508-031957-505530#%0a(:div1 class=expansionhead:)%0a!!!Evidence of understanding in state of the art NLP models %0a-> - AlbertL%0a(:div1end:) %0a>>messageitem%3c%3c %0ahttps://openai.com/blog/multimodal-neurons/%0ahttps://openai.com/blog/dall-e/%0aOpen AI has recently been working on several models tying images and language (I highly advise looking at the above articles they are very cool even if you don't have technical background). In some sense these demonstrate a level of understanding beyond the level of the chinese room analogy.%0a%0aIn the Dalle article, they demonstrate that by modifying the best NLP AI we currently have, we can get it to produce images for a fairly wide range of descriptions. There are numerous examples but they demonstrate that the AI has some concept of various objects, styles, times, etc as they can generalize these ideas to things which were definitely never in its training data. One example they give is that you can ask the AI to generate images of an armchair in the shape of an avocado and it will produce many realistic looking images of chairs that look like avocados. This sentence was clearly never in its training data but the AI was able to not only decipher the syntax of the sentence but understand what that means in terms of images.%0a%0aIn the second article, researchers discovered that in another language image AI model they had built, there existed neurons which responded to specific concepts whether the concept was expressed through image or text. The example they gave was a neuron which responded to pictures of people in spiderman costumes, drawn comics of spiderman, and images of the word spider. This demonstrates that the model has some understanding of that entity as a whole. Moreover neuroscientists have also discovered neurons but this time in human brains which respond strongly to a particular object whether in text or image form. The AI shares this common features with the human brain which suggests some understanding beyond just a lookup table.%0a>>%3c%3c%0a#foxend 210508-031957-505530#%0a[[#expansionsend]]%0a%0a----%0a%25red%25 '''Add an expansion:'''%0a%0a(:if [ exists GradebookExpansions.{$Name}-{$Author} || equal {$Author} {$:Author} ] :)%0a%0a(:else:)%0a%0a(:foxform Site.FoxForms#newexpansion:)%0a%0a(:ifend:)%0a%0a----%0a----%0a%0a!!Comments%0a#foxbegin 210513-202450-799780#%0a(:div1 class=messagehead:)%0a>>rfloat%3c%3c   %0a[-13.05.2021 - 13:24-] &nbsp; %0a>>%3c%3c%0a(:if1 authgroup @tas:)%0a>>rfloat%3c%3c%0a{[foxdelrange button 210513-202450-799780 {$FullName} ]}%0a>>%3c%3c%0a(:if1end:)%0a!!!!!saumyaB%0a(:div1end:) %0a>>messageitem%3c%3c %0a''''''%0a>>messageitem%3c%3c%0aI've never heard of this argument before, but that's a valid point. I think that this ties a lot into our discussions about well-formed sentences that don't convey too much meaning. %0a>>%3c%3c%0a#foxend 210513-202450-799780#%0a%0a%0a%0a(:section: C:)%0a(:Category: Varia:)
time=1620937490
author:1620937490=saumyaB
diff:1620937490:1620443997:=82,99d81%0a%3c #foxbegin 210513-202450-799780#%0a%3c (:div1 class=messagehead:)%0a%3c >>rfloat%3c%3c   %0a%3c [-13.05.2021 - 13:24-] &nbsp; %0a%3c >>%3c%3c%0a%3c (:if1 authgroup @tas:)%0a%3c >>rfloat%3c%3c%0a%3c {[foxdelrange button 210513-202450-799780 {$FullName} ]}%0a%3c >>%3c%3c%0a%3c (:if1end:)%0a%3c !!!!!saumyaB%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c ''''''%0a%3c >>messageitem%3c%3c%0a%3c I've never heard of this argument before, but that's a valid point. I think that this ties a lot into our discussions about well-formed sentences that don't convey too much meaning. %0a%3c >>%3c%3c%0a%3c #foxend 210513-202450-799780#%0a
host:1620937490=128.237.82.1
author:1620443997=AlbertL
diff:1620443997:1620419802:=50,64c50%0a%3c #foxbegin 210508-031957-505530#%0a%3c (:div1 class=expansionhead:)%0a%3c !!!Evidence of understanding in state of the art NLP models %0a%3c -> - AlbertL%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c https://openai.com/blog/multimodal-neurons/%0a%3c https://openai.com/blog/dall-e/%0a%3c Open AI has recently been working on several models tying images and language (I highly advise looking at the above articles they are very cool even if you don't have technical background). In some sense these demonstrate a level of understanding beyond the level of the chinese room analogy.%0a%3c %0a%3c In the Dalle article, they demonstrate that by modifying the best NLP AI we currently have, we can get it to produce images for a fairly wide range of descriptions. There are numerous examples but they demonstrate that the AI has some concept of various objects, styles, times, etc as they can generalize these ideas to things which were definitely never in its training data. One example they give is that you can ask the AI to generate images of an armchair in the shape of an avocado and it will produce many realistic looking images of chairs that look like avocados. This sentence was clearly never in its training data but the AI was able to not only decipher the syntax of the sentence but understand what that means in terms of images.%0a%3c %0a%3c In the second article, researchers discovered that in another language image AI model they had built, there existed neurons which responded to specific concepts whether the concept was expressed through image or text. The example they gave was a neuron which responded to pictures of people in spiderman costumes, drawn comics of spiderman, and images of the word spider. This demonstrates that the model has some understanding of that entity as a whole. Moreover neuroscientists have also discovered neurons but this time in human brains which respond strongly to a particular object whether in text or image form. The AI shares this common features with the human brain which suggests some understanding beyond just a lookup table.%0a%3c >>%3c%3c%0a%3c #foxend 210508-031957-505530#%0a---%0a> %0a
host:1620443997=67.163.151.95
author:1620419802=jjmonroe
diff:1620419802:1620419802:=1,72d0%0a%3c (:if authgroup @tas:)%0a%3c %0a%3c (:toggle id=gi show="show grading interface" hide="hide grading interface":)%0a%3c %0a%3c >>id=gi%3c%3c%0a%3c %0a%3c [[GradebookArticles.{$Name}|See article in gradebook]] \\%0a%3c [[{$FullName}?action=diff|See all changes to article]]%0a%3c %0a%3c (:foxform Site.FoxForms#gradeitem:)%0a%3c %0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c >>%3c%3c%0a%3c %0a%3c ----%0a%3c %0a%3c (:ifend:)%0a%3c %0a%3c [[!Varia]]%0a%3c %0a%3c !Searles Chinese Room Argument%0a%3c %0a%3c :Author: jjmonroe%0a%3c %0a%3c '''Summary:''' \\%0a%3c %0a%3c [[#summary]]%0a%3c %0a%3c An exploration of the difference between "understanding" language and manipulating symbols%0a%3c %0a%3c [[#summaryends]]%0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c One of the major philosophical arguments against computers being able to think in the way that humans do (and by extension against the use of the Turing test as a measure of artificial intelligence), introduced in 1980 by John Searle, has its roots in linguistics as a measure for understanding. The argument, commonly referred to as "the Chinese Room" argument, imagines a person who speaks and understands only English being trapped in a room where he has a manual of instructions on how to operate on Chinese language documents. Following the manual, the man takes in pages of Chinese characters slipped under the door, performs the specified operations based on them, and slips the reply back out under the door. To the person on the outside (analogous to the one performing the Turing test), it would appear that the person inside is reading their messages and replying based on the content. In actuality, the person inside is doing pure symbol manipulation: moving around letters, instead of processing words. The conclusion of this argument is that because the person following the program in the room can feasibly reply in a language they do not understand, formulating coherent responses by pure symbol manipulation, an AI formulating a coherent reply is not sufficient to demonstrate true understanding.%0a%3c %0a%3c This ties in to the Pragmatics section of our course. In the same way there could be a program that follows all the morphological or syntactic rules of a language, there could conceivably be one that follows the rules of content as well, creating well-formed responses without ever touching on the content of the words or sentences.%0a%3c %0a%3c Source:%0a%3c https://plato.stanford.edu/entries/chinese-room/#ChinRoomArgu%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a%3c ----%0a%3c %0a%3c !!Expansions:%0a%3c [[#expansions]]%0a%3c %0a%3c [[#expansionsend]]%0a%3c %0a%3c ----%0a%3c %25red%25 '''Add an expansion:'''%0a%3c %0a%3c (:if [ exists GradebookExpansions.{$Name}-{$Author} || equal {$Author} {$:Author} ] :)%0a%3c %0a%3c (:else:)%0a%3c %0a%3c (:foxform Site.FoxForms#newexpansion:)%0a%3c %0a%3c (:ifend:)%0a%3c %0a%3c ----%0a%3c ----%0a%3c %0a%3c !!Comments%0a%3c %0a%3c %0a%3c %0a%3c (:section: C:)%0a%3c (:Category: Varia:)%0a\ No newline at end of file%0a
host:1620419802=73.174.7.241
