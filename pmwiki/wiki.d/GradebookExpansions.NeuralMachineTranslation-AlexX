version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36
author=TA_audrey
charset=UTF-8
csum=
ctime=1620432529
host=69.218.234.170
name=GradebookExpansions.NeuralMachineTranslation-AlexX
rev=2
targets=Articles.NeuralMachineTranslation,Profiles.Aryans
text=:Category: Varia%0a:Expansion: Explainability in NMT%0a:Author: AlexX%0a:Original: [[Articles.NeuralMachineTranslation|NeuralMachineTranslation]] %0a:OriginalAuthor: [[Profiles.aryans|aryans]]%0a:Section: B%0a:Completed: 07.05.2021 - 17:08%0a:Status: complete%0a%0a(:foxform Site.FoxForms#gradeExpansion:)%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a%0a%25red%25 '''Grading History'''%0a%0a[[#history]]%0a#foxbegin 210511-234505-387460#%0a* [-11.05.2021 - 16:45-] || TA_audrey marked as complete%0a#foxend 210511-234505-387460#%0a[[#historyend]]%0a%0a%25red%25 '''Comments to student'''%0a%0a[[#comments]]%0a%0a[[#commentsend]]%0a%0a----%0a----%0a!!%0a%0a%0a----%0a[[#content]]%0a%0aWhile like you mention, end-to-end NMT models are in general quite difficult to explain, it turns out that certain "attentional" models allow us to glean quite a bit of insight into their operation. Essentially, attention is a technique where the model learns to "pay attention" to various parts of the input sentence (in language A) as it generates the output sentence (in language B). %0a%0aHere's a graphic illustrating attention in English to French translation. The brighter a spot is, the more attention is paid to it:%0ahttps://paperswithcode.com/media/methods/Screen_Shot_2020-05-24_at_7.58.36_PM.png%0a%0aAs we might expect, when the model generates a word in French, it pays the most attention to the corresponding English word in the input sentence (i.e. when generating européenne, European is the word that is paid the most attention). This seemingly implies that our attentional mechanism has some sense of the syntactic structure of both languages. Of course, this nice pattern is aided by the fact that French and English are fairly similar languages; I have no idea if it would also appear when translating from English to a language with wildly different syntax. %0a%0aSource:%0a%0ahttps://arxiv.org/abs/1409.0473%0a%0ahttps://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html%0a%0a[[#contentends]]%0a----%0a(:Category:)%0a(:GradedBy: TA_audrey:)
time=1620776705
author:1620776705=TA_audrey
diff:1620776705:1620432529:=8,9c8,9%0a%3c :Status: complete%0a%3c %0a---%0a> :Status: ungraded%0a> %0a17,19c17%0a%3c #foxbegin 210511-234505-387460#%0a%3c * [-11.05.2021 - 16:45-] || TA_audrey marked as complete%0a%3c #foxend 210511-234505-387460#%0a---%0a> %0a51,52c49%0a%3c (:Category:)%0a%3c (:GradedBy: TA_audrey:)%0a\ No newline at end of file%0a---%0a> (:Category:)%0a\ No newline at end of file%0a
host:1620776705=69.218.234.170
author:1620432529=AlexX
diff:1620432529:1620432529:=1,49d0%0a%3c :Category: Varia%0a%3c :Expansion: Explainability in NMT%0a%3c :Author: AlexX%0a%3c :Original: [[Articles.NeuralMachineTranslation|NeuralMachineTranslation]] %0a%3c :OriginalAuthor: [[Profiles.aryans|aryans]]%0a%3c :Section: B%0a%3c :Completed: 07.05.2021 - 17:08%0a%3c :Status: ungraded%0a%3c %0a%3c (:foxform Site.FoxForms#gradeExpansion:)%0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c %0a%3c %25red%25 '''Grading History'''%0a%3c %0a%3c [[#history]]%0a%3c %0a%3c [[#historyend]]%0a%3c %0a%3c %25red%25 '''Comments to student'''%0a%3c %0a%3c [[#comments]]%0a%3c %0a%3c [[#commentsend]]%0a%3c %0a%3c ----%0a%3c ----%0a%3c !!%0a%3c %0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c While like you mention, end-to-end NMT models are in general quite difficult to explain, it turns out that certain "attentional" models allow us to glean quite a bit of insight into their operation. Essentially, attention is a technique where the model learns to "pay attention" to various parts of the input sentence (in language A) as it generates the output sentence (in language B). %0a%3c %0a%3c Here's a graphic illustrating attention in English to French translation. The brighter a spot is, the more attention is paid to it:%0a%3c https://paperswithcode.com/media/methods/Screen_Shot_2020-05-24_at_7.58.36_PM.png%0a%3c %0a%3c As we might expect, when the model generates a word in French, it pays the most attention to the corresponding English word in the input sentence (i.e. when generating européenne, European is the word that is paid the most attention). This seemingly implies that our attentional mechanism has some sense of the syntactic structure of both languages. Of course, this nice pattern is aided by the fact that French and English are fairly similar languages; I have no idea if it would also appear when translating from English to a language with wildly different syntax. %0a%3c %0a%3c Source:%0a%3c %0a%3c https://arxiv.org/abs/1409.0473%0a%3c %0a%3c https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a%3c (:Category:)%0a\ No newline at end of file%0a
host:1620432529=71.206.238.88
