version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36
author=TA_lili
charset=UTF-8
csum=
ctime=1620437284
host=67.171.64.6
name=GradebookExpansions.ForensicLinguistics-CharlieP
rev=2
targets=Articles.ForensicLinguistics,Profiles.AlexanderW
text=:Category: Varia%0a:Expansion: Spam Filtering%0a:Author: CharlieP%0a:Original: [[Articles.ForensicLinguistics|ForensicLinguistics]] %0a:OriginalAuthor: [[Profiles.AlexanderW|AlexanderW]]%0a:Section: D%0a:Completed: 07.05.2021 - 18:28%0a:Status: complete%0a%0a(:foxform Site.FoxForms#gradeExpansion:)%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a%0a%25red%25 '''Grading History'''%0a%0a[[#history]]%0a#foxbegin 210511-013315-544570#%0a* [-10.05.2021 - 18:33-] || TA_lili marked as complete%0a#foxend 210511-013315-544570#%0a[[#historyend]]%0a%0a%25red%25 '''Comments to student'''%0a%0a[[#comments]]%0a%0a[[#commentsend]]%0a%0a----%0a----%0a!!%0a%0a%0a----%0a[[#content]]%0a%0aSpam filtering, interestingly, uses some of the same exact techniques of Forensic linguistics, except instead of trying to find one specific text that is similar to the given one, we're trying to classify the given text as "spam" or "not spam" given a corpus of spam and non-spam messages. In forensic linguistics, you're typically running an algorithm that compares your sample with many other texts in the corpus to find one that's most similar, but this is way too slow to do for spam filtering, since we don't have time to compare to the whole corpus. Instead, we can train a classifier on the corpus and use this much faster, but slightly less accurate, classifier to determine if a sample is spam or not. One such of example of a classifier is a Hidden Markov Model, which uses a very simple chain of probabilities to check each word in the sample, which, albeit very simple, is very effective. %0a%0aSource: https://www.networkworld.com/article/2296297/the-antispam-man.html%0a%0a[[#contentends]]%0a----%0a(:Category:)%0a(:GradedBy: TA_lili:)
time=1620696794
author:1620696794=TA_lili
diff:1620696794:1620437284:=8,9c8,9%0a%3c :Status: complete%0a%3c %0a---%0a> :Status: ungraded%0a> %0a17,19c17%0a%3c #foxbegin 210511-013315-544570#%0a%3c * [-10.05.2021 - 18:33-] || TA_lili marked as complete%0a%3c #foxend 210511-013315-544570#%0a---%0a> %0a42,43c40%0a%3c (:Category:)%0a%3c (:GradedBy: TA_lili:)%0a\ No newline at end of file%0a---%0a> (:Category:)%0a\ No newline at end of file%0a
host:1620696794=67.171.64.6
author:1620437284=CharlieP
diff:1620437284:1620437284:=1,40d0%0a%3c :Category: Varia%0a%3c :Expansion: Spam Filtering%0a%3c :Author: CharlieP%0a%3c :Original: [[Articles.ForensicLinguistics|ForensicLinguistics]] %0a%3c :OriginalAuthor: [[Profiles.AlexanderW|AlexanderW]]%0a%3c :Section: D%0a%3c :Completed: 07.05.2021 - 18:28%0a%3c :Status: ungraded%0a%3c %0a%3c (:foxform Site.FoxForms#gradeExpansion:)%0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c %0a%3c %25red%25 '''Grading History'''%0a%3c %0a%3c [[#history]]%0a%3c %0a%3c [[#historyend]]%0a%3c %0a%3c %25red%25 '''Comments to student'''%0a%3c %0a%3c [[#comments]]%0a%3c %0a%3c [[#commentsend]]%0a%3c %0a%3c ----%0a%3c ----%0a%3c !!%0a%3c %0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c Spam filtering, interestingly, uses some of the same exact techniques of Forensic linguistics, except instead of trying to find one specific text that is similar to the given one, we're trying to classify the given text as "spam" or "not spam" given a corpus of spam and non-spam messages. In forensic linguistics, you're typically running an algorithm that compares your sample with many other texts in the corpus to find one that's most similar, but this is way too slow to do for spam filtering, since we don't have time to compare to the whole corpus. Instead, we can train a classifier on the corpus and use this much faster, but slightly less accurate, classifier to determine if a sample is spam or not. One such of example of a classifier is a Hidden Markov Model, which uses a very simple chain of probabilities to check each word in the sample, which, albeit very simple, is very effective. %0a%3c %0a%3c Source: https://www.networkworld.com/article/2296297/the-antispam-man.html%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a%3c (:Category:)%0a\ No newline at end of file%0a
host:1620437284=74.109.251.161
