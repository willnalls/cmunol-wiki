version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36
author=TA_lili
charset=UTF-8
csum=
ctime=1620419802
host=74.111.97.246
name=GradebookArticles.SearlesChineseRoomArgument
rev=2
targets=
text=:Category: Varia%0a:Essential: {Category.Varia$:essential}%0a:Title: Searles Chinese Room Argument%0a:Author: jjmonroe%0a:Section: C%0a:Completed: 07.05.2021 - 13:36%0a:Status: complete%0a%0a(:foxform Site.FoxForms#gradeitem:)%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a----%0a%0a%0a%25blue%25 '''Grading History'''%0a%0a[[#history]]%0a#foxbegin 210510-201126-635140#%0a* [-10.05.2021 - 13:11-] || TA_lili marked as complete%0a#foxend 210510-201126-635140#%0a[[#historyend]]%0a%0a%25blue%25 '''Comments for student'''%0a%0a[[#comments]]%0a%0a[[#commentsend]]%0a%0a----%0a----%0a!!%0a%0aSummary: \\%0a%0a[[#summary]]%0a%0aAn exploration of the difference between "understanding" language and manipulating symbols%0a%0a[[#summaryends]]%0a%0a----%0a[[#content]]%0a%0aOne of the major philosophical arguments against computers being able to think in the way that humans do (and by extension against the use of the Turing test as a measure of artificial intelligence), introduced in 1980 by John Searle, has its roots in linguistics as a measure for understanding. The argument, commonly referred to as "the Chinese Room" argument, imagines a person who speaks and understands only English being trapped in a room where he has a manual of instructions on how to operate on Chinese language documents. Following the manual, the man takes in pages of Chinese characters slipped under the door, performs the specified operations based on them, and slips the reply back out under the door. To the person on the outside (analogous to the one performing the Turing test), it would appear that the person inside is reading their messages and replying based on the content. In actuality, the person inside is doing pure symbol manipulation: moving around letters, instead of processing words. The conclusion of this argument is that because the person following the program in the room can feasibly reply in a language they do not understand, formulating coherent responses by pure symbol manipulation, an AI formulating a coherent reply is not sufficient to demonstrate true understanding.%0a%0aThis ties in to the Pragmatics section of our course. In the same way there could be a program that follows all the morphological or syntactic rules of a language, there could conceivably be one that follows the rules of content as well, creating well-formed responses without ever touching on the content of the words or sentences.%0a%0aSource:%0ahttps://plato.stanford.edu/entries/chinese-room/#ChinRoomArgu%0a%0a[[#contentends]]%0a----%0a(:GradedBy: TA_lili:)
time=1620677485
author:1620677485=TA_lili
diff:1620677485:1620419802:=7,8c7,8%0a%3c :Status: complete%0a%3c %0a---%0a> :Status: ungraded%0a> %0a18,20c18%0a%3c #foxbegin 210510-201126-635140#%0a%3c * [-10.05.2021 - 13:11-] || TA_lili marked as complete%0a%3c #foxend 210510-201126-635140#%0a---%0a> %0a52,53c50%0a%3c ----%0a%3c (:GradedBy: TA_lili:)%0a\ No newline at end of file%0a---%0a> ----%0a\ No newline at end of file%0a
host:1620677485=74.111.97.246
author:1620419802=jjmonroe
diff:1620419802:1620419802:=1,50d0%0a%3c :Category: Varia%0a%3c :Essential: {Category.Varia$:essential}%0a%3c :Title: Searles Chinese Room Argument%0a%3c :Author: jjmonroe%0a%3c :Section: C%0a%3c :Completed: 07.05.2021 - 13:36%0a%3c :Status: ungraded%0a%3c %0a%3c (:foxform Site.FoxForms#gradeitem:)%0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c ----%0a%3c %0a%3c %0a%3c %25blue%25 '''Grading History'''%0a%3c %0a%3c [[#history]]%0a%3c %0a%3c [[#historyend]]%0a%3c %0a%3c %25blue%25 '''Comments for student'''%0a%3c %0a%3c [[#comments]]%0a%3c %0a%3c [[#commentsend]]%0a%3c %0a%3c ----%0a%3c ----%0a%3c !!%0a%3c %0a%3c Summary: \\%0a%3c %0a%3c [[#summary]]%0a%3c %0a%3c An exploration of the difference between "understanding" language and manipulating symbols%0a%3c %0a%3c [[#summaryends]]%0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c One of the major philosophical arguments against computers being able to think in the way that humans do (and by extension against the use of the Turing test as a measure of artificial intelligence), introduced in 1980 by John Searle, has its roots in linguistics as a measure for understanding. The argument, commonly referred to as "the Chinese Room" argument, imagines a person who speaks and understands only English being trapped in a room where he has a manual of instructions on how to operate on Chinese language documents. Following the manual, the man takes in pages of Chinese characters slipped under the door, performs the specified operations based on them, and slips the reply back out under the door. To the person on the outside (analogous to the one performing the Turing test), it would appear that the person inside is reading their messages and replying based on the content. In actuality, the person inside is doing pure symbol manipulation: moving around letters, instead of processing words. The conclusion of this argument is that because the person following the program in the room can feasibly reply in a language they do not understand, formulating coherent responses by pure symbol manipulation, an AI formulating a coherent reply is not sufficient to demonstrate true understanding.%0a%3c %0a%3c This ties in to the Pragmatics section of our course. In the same way there could be a program that follows all the morphological or syntactic rules of a language, there could conceivably be one that follows the rules of content as well, creating well-formed responses without ever touching on the content of the words or sentences.%0a%3c %0a%3c Source:%0a%3c https://plato.stanford.edu/entries/chinese-room/#ChinRoomArgu%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a\ No newline at end of file%0a
host:1620419802=73.174.7.241
