version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36
author=AlexanderW
charset=UTF-8
csum=
ctime=1619933314
host=73.90.192.150
name=Articles.SpeechSynthesis
rev=6
targets=GradebookArticles.SpeechSynthesis,Articles.SpeechSynthesis,Category.Varia
text=(:if authgroup @tas:)%0a%0a(:toggle id=gi show="show grading interface" hide="hide grading interface":)%0a%0a>>id=gi%3c%3c%0a%0a[[GradebookArticles.{$Name}|See article in gradebook]] \\%0a[[{$FullName}?action=diff|See all changes to article]]%0a%0a(:foxform Site.FoxForms#gradeitem:)%0a%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a>>%3c%3c%0a%0a----%0a%0a(:ifend:)%0a%0a[[!Varia]]%0a%0a!Speech Synthesis%0a%0a:Author: NickG%0a%0a'''Summary:''' \\%0a%0a[[#summary]]%0a%0aSpeech synthesis involves a number of methods of turning text into recognizable speech.%0a%0a[[#summaryends]]%0a%0a----%0a[[#content]]%0a%0aThe desire to emulate human speech using alternative methods has been around for a very long time. As far back as the 11th century there have been myths of people creating mechanical objects capable of emulating speech. In the 18th century, a German scientist was actually able to model the human vocal tract to create something capable of producing the vowel sounds. Recently, a lot of research has gone into computer-based systems capable of turning text into speech because of just how useful in would be.%0a%0aIn fact, there are currently a vast number of methods of producing speech from text. A very interesting method is called "formant synthesis." As opposed to a lot of other systems that used pre-recorded samples and play them, this process uses an acoustic model similar to the 18th century one, but much more intricate. When the system reads the text, it creates a generic audio sound but modifies parameters like voicing, fundamental frequency, and noise levels to create the desired sound. Although the produced speech does not sound very natural, this method is good at producing speech which is very easy to understand. The more aspects of the base sound is changed, the more nuanced sounds can be created; modifying things like intonations and pauses leads to very comprehendible speech.%0a%0aAnother method is called "concatenation synthesis," which is what people are more used to and just involves playing recorded speech in the right sequence. Since the sounds are recorded by a human, the individual sounds are very humanistic. However, when a bunch of sound files are strung together for a sentence, it can sounds less and less human the more that is said. This is one difficulty with concatenation synthesis, because there are simply too many ways to say different words depending on how they are used and what is surrounding it.%0a%0aSources: %0a[[https://www.soundonsound.com/techniques/formant-synthesis]]%0a[[http://recherche.ircam.fr/equipes/analyse-synthese/schwarz/publications/icmc2005/Schwarz_ICMC2005_Current-Research.pdf]]%0a%0a[[#contentends]]%0a----%0a----%0a%0a!!Expansions:%0a[[#expansions]]%0a#foxbegin 210502-203107-208810#%0a(:div1 class=expansionhead:)%0a!!!Additional methods for speech synthesis %0a-> - kevinx%0a(:div1end:) %0a>>messageitem%3c%3c %0aThe Wikipedia article for Speech Synthesis offers a look at a few more methods:%0ahttps://en.wikipedia.org/wiki/Speech_synthesis%0a%0aGoogle's DeepMind, for example, is working on Deep learning-based synthesis, which has been applied in Google's WaveNet (https://youtu.be/JjK8apEishQ). This method uses deep learning to generate speech that mimics the vocal and acoustic patterns of existing raw audio samples. Given the investment in this technology, it could lead to a speech synthesizer that applies formant synthesis without humans needing to exhaustively model all the frequencies and waveforms by hand.%0a%0aWhile deep learning is promising for many reasons, there are plenty of problems left to be solved. Some are problems with deep learning in general, for example requiring large datasets and lack of controllability. Others are more specific to speech synthesis. For example, because deep learning averages over the training data, the resulting speech synthesis model can often have a flat cadence or prosody which may sound robotic or unnatural as a result. %0a%0aAs deep learning continues to mature as a field, deep learning-based speech synthesis will no doubt become more robust. With the current level of investment into text-to-speech programs such as AI assistants, it will be interesting to see which method of speech synthesis ultimately becomes the standard.%0a>>%3c%3c%0a#foxend 210502-203107-208810#%0a[[#expansionsend]]%0a%0a----%0a%25red%25 '''Add an expansion:'''%0a%0a(:if [ exists GradebookExpansions.{$Name}-{$Author} || equal {$Author} {$:Author} ] :)%0a%0a(:else:)%0a%0a(:foxform Site.FoxForms#newexpansion:)%0a%0a(:ifend:)%0a%0a----%0a----%0a%0a!!Comments%0a#foxbegin 210507-023911-666290#%0a(:div1 class=messagehead:)%0a>>rfloat%3c%3c   %0a[-06.05.2021 - 19:39-] &nbsp; %0a>>%3c%3c%0a(:if1 authgroup @tas:)%0a>>rfloat%3c%3c%0a{[foxdelrange button 210507-023911-666290 {$FullName} ]}%0a>>%3c%3c%0a(:if1end:)%0a!!!!!AlexanderW%0a(:div1end:) %0a>>messageitem%3c%3c %0a''''''%0a>>messageitem%3c%3c%0aWith regards to Kevin's comment, I believe that voice changers are pretty good these days. By just having an actor speak the lines, then having a - more specialized, or even AI-trained - voice-changer to modulate their voice to emulate whoever; I agree, that does sound very scary! %0a>>%3c%3c%0a#foxend 210507-023911-666290#%0a#foxbegin 210502-185801-241750#%0a(:div1 class=messagehead:)%0a>>rfloat%3c%3c   %0a[-02.05.2021 - 11:58-] &nbsp; %0a>>%3c%3c%0a(:if1 authgroup @tas:)%0a>>rfloat%3c%3c%0a{[foxdelrange button 210502-185801-241750 {$FullName} ]}%0a>>%3c%3c%0a(:if1end:)%0a!!!!!kevinx%0a(:div1end:) %0a>>messageitem%3c%3c %0a''''''%0a>>messageitem%3c%3c%0aI'm both looking forward to and dreading text-to-speech systems that sound natural and can mimic real voices. Deepfaking speech samples would probably not be a good thing for public trust. %0a>>%3c%3c%0a#foxend 210502-185801-241750#%0a%0a%0a%0a(:section: C:)%0a(:Category: Varia:)
time=1620355150
author:1620355150=AlexanderW
diff:1620355150:1619987467:=86,103d85%0a%3c #foxbegin 210507-023911-666290#%0a%3c (:div1 class=messagehead:)%0a%3c >>rfloat%3c%3c   %0a%3c [-06.05.2021 - 19:39-] &nbsp; %0a%3c >>%3c%3c%0a%3c (:if1 authgroup @tas:)%0a%3c >>rfloat%3c%3c%0a%3c {[foxdelrange button 210507-023911-666290 {$FullName} ]}%0a%3c >>%3c%3c%0a%3c (:if1end:)%0a%3c !!!!!AlexanderW%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c ''''''%0a%3c >>messageitem%3c%3c%0a%3c With regards to Kevin's comment, I believe that voice changers are pretty good these days. By just having an actor speak the lines, then having a - more specialized, or even AI-trained - voice-changer to modulate their voice to emulate whoever; I agree, that does sound very scary! %0a%3c >>%3c%3c%0a%3c #foxend 210507-023911-666290#%0a
host:1620355150=73.90.192.150
author:1619987467=kevinx
diff:1619987467:1619981881:=53,68c53%0a%3c #foxbegin 210502-203107-208810#%0a%3c (:div1 class=expansionhead:)%0a%3c !!!Additional methods for speech synthesis %0a%3c -> - kevinx%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c The Wikipedia article for Speech Synthesis offers a look at a few more methods:%0a%3c https://en.wikipedia.org/wiki/Speech_synthesis%0a%3c %0a%3c Google's DeepMind, for example, is working on Deep learning-based synthesis, which has been applied in Google's WaveNet (https://youtu.be/JjK8apEishQ). This method uses deep learning to generate speech that mimics the vocal and acoustic patterns of existing raw audio samples. Given the investment in this technology, it could lead to a speech synthesizer that applies formant synthesis without humans needing to exhaustively model all the frequencies and waveforms by hand.%0a%3c %0a%3c While deep learning is promising for many reasons, there are plenty of problems left to be solved. Some are problems with deep learning in general, for example requiring large datasets and lack of controllability. Others are more specific to speech synthesis. For example, because deep learning averages over the training data, the resulting speech synthesis model can often have a flat cadence or prosody which may sound robotic or unnatural as a result. %0a%3c %0a%3c As deep learning continues to mature as a field, deep learning-based speech synthesis will no doubt become more robust. With the current level of investment into text-to-speech programs such as AI assistants, it will be interesting to see which method of speech synthesis ultimately becomes the standard.%0a%3c >>%3c%3c%0a%3c #foxend 210502-203107-208810#%0a---%0a> %0a
host:1619987467=73.154.247.242
author:1619981881=kevinx
diff:1619981881:1619933385:=71,88d70%0a%3c #foxbegin 210502-185801-241750#%0a%3c (:div1 class=messagehead:)%0a%3c >>rfloat%3c%3c   %0a%3c [-02.05.2021 - 11:58-] &nbsp; %0a%3c >>%3c%3c%0a%3c (:if1 authgroup @tas:)%0a%3c >>rfloat%3c%3c%0a%3c {[foxdelrange button 210502-185801-241750 {$FullName} ]}%0a%3c >>%3c%3c%0a%3c (:if1end:)%0a%3c !!!!!kevinx%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c ''''''%0a%3c >>messageitem%3c%3c%0a%3c I'm both looking forward to and dreading text-to-speech systems that sound natural and can mimic real voices. Deepfaking speech samples would probably not be a good thing for public trust. %0a%3c >>%3c%3c%0a%3c #foxend 210502-185801-241750#%0a
host:1619981881=73.154.247.242
author:1619933385=NickG
diff:1619933385:1619933358:=38d37%0a%3c %0a40d38%0a%3c %0a43c41%0a%3c Sources: %0a---%0a> Sources:%0a
host:1619933385=74.109.251.161
author:1619933358=NickG
diff:1619933358:1619933314:=37,43c37,43%0a%3c The desire to emulate human speech using alternative methods has been around for a very long time. As far back as the 11th century there have been myths of people creating mechanical objects capable of emulating speech. In the 18th century, a German scientist was actually able to model the human vocal tract to create something capable of producing the vowel sounds. Recently, a lot of research has gone into computer-based systems capable of turning text into speech because of just how useful in would be.%0a%3c In fact, there are currently a vast number of methods of producing speech from text. A very interesting method is called "formant synthesis." As opposed to a lot of other systems that used pre-recorded samples and play them, this process uses an acoustic model similar to the 18th century one, but much more intricate. When the system reads the text, it creates a generic audio sound but modifies parameters like voicing, fundamental frequency, and noise levels to create the desired sound. Although the produced speech does not sound very natural, this method is good at producing speech which is very easy to understand. The more aspects of the base sound is changed, the more nuanced sounds can be created; modifying things like intonations and pauses leads to very comprehendible speech.%0a%3c Another method is called "concatenation synthesis," which is what people are more used to and just involves playing recorded speech in the right sequence. Since the sounds are recorded by a human, the individual sounds are very humanistic. However, when a bunch of sound files are strung together for a sentence, it can sounds less and less human the more that is said. This is one difficulty with concatenation synthesis, because there are simply too many ways to say different words depending on how they are used and what is surrounding it.%0a%3c %0a%3c Sources:%0a%3c [[https://www.soundonsound.com/techniques/formant-synthesis]]%0a%3c [[http://recherche.ircam.fr/equipes/analyse-synthese/schwarz/publications/icmc2005/Schwarz_ICMC2005_Current-Research.pdf]]%0a---%0a> The desire to emulate human speech using alternative methods has been around for a very long time. As far back as the 11th century there have been myths of people creating mechanical objects capable of emulating speech. In the 18th century, a German scientist was actually able to model the human vocal tract to create something capable of producing the vowel sounds. Recently, a lot of research has gone into computer-based systems capable of turning text into speech because of just how useful in would be.%0a> In fact, there are currently a vast number of methods of producing speech from text. A very interesting method is called "formant synthesis." As opposed to a lot of other systems that used pre-recorded samples and play them, this process uses an acoustic model similar to the 18th century one, but much more intricate. When the system reads the text, it creates a generic audio sound but modifies parameters like voicing, fundamental frequency, and noise levels to create the desired sound. Although the produced speech does not sound very natural, this method is good at producing speech which is very easy to understand. The more aspects of the base sound is changed, the more nuanced sounds can be created; modifying things like intonations and pauses leads to very comprehendible speech.%0a> Another method is called "concatenation synthesis," which is what people are more used to and just involves playing recorded speech in the right sequence. Since the sounds are recorded by a human, the individual sounds are very humanistic. However, when a bunch of sound files are strung together for a sentence, it can sounds less and less human the more that is said. This is one difficulty with concatenation synthesis, because there are simply too many ways to say different words depending on how they are used and what is surrounding it.%0a> %0a> Sources:%0a> https://www.soundonsound.com/techniques/formant-synthesis%0a> http://recherche.ircam.fr/equipes/analyse-synthese/schwarz/publications/icmc2005/Schwarz_ICMC2005_Current-Research.pdf%0a
host:1619933358=74.109.251.161
author:1619933314=NickG
diff:1619933314:1619933314:=1,73d0%0a%3c (:if authgroup @tas:)%0a%3c %0a%3c (:toggle id=gi show="show grading interface" hide="hide grading interface":)%0a%3c %0a%3c >>id=gi%3c%3c%0a%3c %0a%3c [[GradebookArticles.{$Name}|See article in gradebook]] \\%0a%3c [[{$FullName}?action=diff|See all changes to article]]%0a%3c %0a%3c (:foxform Site.FoxForms#gradeitem:)%0a%3c %0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c >>%3c%3c%0a%3c %0a%3c ----%0a%3c %0a%3c (:ifend:)%0a%3c %0a%3c [[!Varia]]%0a%3c %0a%3c !Speech Synthesis%0a%3c %0a%3c :Author: NickG%0a%3c %0a%3c '''Summary:''' \\%0a%3c %0a%3c [[#summary]]%0a%3c %0a%3c Speech synthesis involves a number of methods of turning text into recognizable speech.%0a%3c %0a%3c [[#summaryends]]%0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c The desire to emulate human speech using alternative methods has been around for a very long time. As far back as the 11th century there have been myths of people creating mechanical objects capable of emulating speech. In the 18th century, a German scientist was actually able to model the human vocal tract to create something capable of producing the vowel sounds. Recently, a lot of research has gone into computer-based systems capable of turning text into speech because of just how useful in would be.%0a%3c In fact, there are currently a vast number of methods of producing speech from text. A very interesting method is called "formant synthesis." As opposed to a lot of other systems that used pre-recorded samples and play them, this process uses an acoustic model similar to the 18th century one, but much more intricate. When the system reads the text, it creates a generic audio sound but modifies parameters like voicing, fundamental frequency, and noise levels to create the desired sound. Although the produced speech does not sound very natural, this method is good at producing speech which is very easy to understand. The more aspects of the base sound is changed, the more nuanced sounds can be created; modifying things like intonations and pauses leads to very comprehendible speech.%0a%3c Another method is called "concatenation synthesis," which is what people are more used to and just involves playing recorded speech in the right sequence. Since the sounds are recorded by a human, the individual sounds are very humanistic. However, when a bunch of sound files are strung together for a sentence, it can sounds less and less human the more that is said. This is one difficulty with concatenation synthesis, because there are simply too many ways to say different words depending on how they are used and what is surrounding it.%0a%3c %0a%3c Sources:%0a%3c https://www.soundonsound.com/techniques/formant-synthesis%0a%3c http://recherche.ircam.fr/equipes/analyse-synthese/schwarz/publications/icmc2005/Schwarz_ICMC2005_Current-Research.pdf%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a%3c ----%0a%3c %0a%3c !!Expansions:%0a%3c [[#expansions]]%0a%3c %0a%3c [[#expansionsend]]%0a%3c %0a%3c ----%0a%3c %25red%25 '''Add an expansion:'''%0a%3c %0a%3c (:if [ exists GradebookExpansions.{$Name}-{$Author} || equal {$Author} {$:Author} ] :)%0a%3c %0a%3c (:else:)%0a%3c %0a%3c (:foxform Site.FoxForms#newexpansion:)%0a%3c %0a%3c (:ifend:)%0a%3c %0a%3c ----%0a%3c ----%0a%3c %0a%3c !!Comments%0a%3c %0a%3c %0a%3c %0a%3c (:section: C:)%0a%3c (:Category: Varia:)%0a\ No newline at end of file%0a
host:1619933314=74.109.251.161
