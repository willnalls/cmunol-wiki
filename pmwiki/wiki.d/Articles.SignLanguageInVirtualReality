version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36
author=chester_g
charset=UTF-8
csum=
ctime=1619985863
host=71.206.239.38
name=Articles.SignLanguageInVirtualReality
rev=5
targets=GradebookArticles.SignLanguageInVirtualReality,Articles.SignLanguageInVirtualReality,Category.SignLanguage
text=(:if authgroup @tas:)%0a%0a(:toggle id=gi show="show grading interface" hide="hide grading interface":)%0a%0a>>id=gi%3c%3c%0a%0a[[GradebookArticles.{$Name}|See article in gradebook]] \\%0a[[{$FullName}?action=diff|See all changes to article]]%0a%0a(:foxform Site.FoxForms#gradeitem:)%0a%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a>>%3c%3c%0a%0a----%0a%0a(:ifend:)%0a%0a[[!SignLanguage]]%0a%0a!Sign Language in Virtual Reality%0a%0a:Author: kevinx%0a%0a'''Summary:''' \\%0a%0a[[#summary]]%0a%0aThe challenges and benefits of bringing Sign Language to Virtual Reality%0a%0a[[#summaryends]]%0a%0a----%0a[[#content]]%0a%0aFor those who sign as their primary language, there has never been a sufficient digital equivalent to the language's expressiveness and sense of presence. Texting, for example, uses written language and does not carry the same raw emotion as sign language. Recently, however, the increased affordability of hand-tracking technology in VR headsets has offered a potential look into the future.%0a%0aBefore hand-tracking, deaf and mute users may have had a lot of trouble interpreting spoken language in VR. Many VR social games use virtual avatars whose mouths open and close ambiguously when the user is speaking. Without the ability to accurately lip read or sign, many users felt alienated by VR social games.%0a%0aRecently, in communities such as VRChat, users have been able to program downloadable modifications that make it possible to use hand-tracking controllers to approximate sign language gestures and handshapes. However, the technology is far from mature enough to provide a one-to-one experience equivalent to reality. For example, many hand-tracking technologies only consider whether a finger is "gripped" or "open", not allowing for further subtleties such as if a finger is crossed over another to represent letters such as "P" or "Q" in ASL or whether fingers are partially bent. To compensate, VRChat users have come up with a few VR-specific alternatives for many gestures/handshapes, possibly leading to a new digital sign language. %0a%0aA fully functional sign language suite in VR would have many benefits for the deaf and mute communities: for one, it would provide a space for deaf and mute communities to fully express themselves digitally. The system would replace group video chatting which doesn't provide the same sense of proximity and presence as sign language in real life. Many deaf and mute users who may have felt isolated in their local communities would be able to connect with others across the world in a manner unhindered by technologies which may not have considered them as first priorities. Further, it could contribute to the ability to teach students sign language remotely or gamify sign language education for young learners. %0a%0aThere is still much progress to be made in the field of VR sign language, but its development is definitely exciting to follow.%0a%0aSources:%0ahttps://uploadvr.com/sign-language-vr-asl/%0ahttps://www.youtube.com/watch?v=A-vYOlN5qQY%0a%0a[[#contentends]]%0a----%0a----%0a%0a!!Expansions:%0a[[#expansions]]%0a#foxbegin 210508-031541-992410#%0a(:div1 class=expansionhead:)%0a!!!Computer Vision in Hand Tracking for Sign Language %0a-> - CharlieP%0a(:div1end:) %0a>>messageitem%3c%3c %0aThe current technology of sign language in VR is through tracking of the hands as rigid bodies, that is, that the individual motion of the fingers or arms isn't tracked, only the position and rotation of the hand in space, as well as whether the controller is "gripped" or "open" is tracked. Something that could make sign language in VR much more natural is tracking of the hands and arms using computer vision. This method would track the individual fingers as well as the arms, and possibly the face of the speaker, to better convey more sign language in VR, as well as lower the learning curve for new users. I think that the reason finger tracking in VR isn't more popular is that it's not necessary for playing games, and typically you would be rotating in your room, not just facing one direction. Typically, you don't rotate to various positions when you're having a conversation in real life, so this solution may be viable. %0a%0aHere's a blog post illustrating some of Google's hand recognition technology: %0ahttps://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html%0a%0aSources: %0ahttps://towardsdatascience.com/sign-language-recognition-using-deep-learning-6549268c60bd%0ahttps://paperswithcode.com/task/sign-language-recognition%0a%0a>>%3c%3c%0a#foxend 210508-031541-992410#%0a#foxbegin 210508-212736-847940#%0a(:div1 class=expansionhead:)%0a!!!VR and Computer Vision as it benefits Sign Language and Communications %0a-> - chester_g%0a(:div1end:) %0a>>messageitem%3c%3c %0aTo expand off of both kevin and charlie, I believe another interesting topic of relevance is the ability for VR and AR to use computer vision to understand others. With technology like google glasses and futuristics concepts where we can use technologically advanced vision to view the world around us, it might be beneficial to consider how this hand recognition could factor in. Like Charlie mentioned, computer vision is a crucial technology. However, it is easier for tracking other individuals rather than yourself due to perspective issues. Therefore, with the incorporation of computer vision and tech like google glasses, society could progress to better integrate ASL and other sign languages with instant visual translation. %0a%0ahttps://uploadvr.com/sign-language-vr-asl/ %0a>>%3c%3c%0a#foxend 210508-212736-847940#%0a[[#expansionsend]]%0a%0a----%0a%25red%25 '''Add an expansion:'''%0a%0a(:if [ exists GradebookExpansions.{$Name}-{$Author} || equal {$Author} {$:Author} ] :)%0a%0a(:else:)%0a%0a(:foxform Site.FoxForms#newexpansion:)%0a%0a(:ifend:)%0a%0a----%0a----%0a%0a!!Comments%0a#foxbegin 210505-213456-221890#%0a(:div1 class=messagehead:)%0a>>rfloat%3c%3c   %0a[-05.05.2021 - 14:34-] &nbsp; %0a>>%3c%3c%0a(:if1 authgroup @tas:)%0a>>rfloat%3c%3c%0a{[foxdelrange button 210505-213456-221890 {$FullName} ]}%0a>>%3c%3c%0a(:if1end:)%0a!!!!!MindeeL%0a(:div1end:) %0a>>messageitem%3c%3c %0a''''''%0a>>messageitem%3c%3c%0aThis is really cool. I bet it is not only challenging to get the handshapes needed for sign language, but also all the other things that are important to signing such as facial and body movement.  %0a>>%3c%3c%0a#foxend 210505-213456-221890#%0a#foxbegin 210505-213455-76480#%0a(:div1 class=messagehead:)%0a>>rfloat%3c%3c   %0a[-05.05.2021 - 14:34-] &nbsp; %0a>>%3c%3c%0a(:if1 authgroup @tas:)%0a>>rfloat%3c%3c%0a{[foxdelrange button 210505-213455-76480 {$FullName} ]}%0a>>%3c%3c%0a(:if1end:)%0a!!!!!MindeeL%0a(:div1end:) %0a>>messageitem%3c%3c %0a''''''%0a>>messageitem%3c%3c%0aThis is really cool. I bet it is not only challenging to get the handshapes needed for sign language, but also all the other things that are important to signing such as facial and body movement.  %0a>>%3c%3c%0a#foxend 210505-213455-76480#%0a%0a%0a%0a(:section: D:)%0a(:Category: SignLanguage:)
time=1620509255
author:1620509255=chester_g
diff:1620509255:1620443740:=74,84d73%0a%3c #foxbegin 210508-212736-847940#%0a%3c (:div1 class=expansionhead:)%0a%3c !!!VR and Computer Vision as it benefits Sign Language and Communications %0a%3c -> - chester_g%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c To expand off of both kevin and charlie, I believe another interesting topic of relevance is the ability for VR and AR to use computer vision to understand others. With technology like google glasses and futuristics concepts where we can use technologically advanced vision to view the world around us, it might be beneficial to consider how this hand recognition could factor in. Like Charlie mentioned, computer vision is a crucial technology. However, it is easier for tracking other individuals rather than yourself due to perspective issues. Therefore, with the incorporation of computer vision and tech like google glasses, society could progress to better integrate ASL and other sign languages with instant visual translation. %0a%3c %0a%3c https://uploadvr.com/sign-language-vr-asl/ %0a%3c >>%3c%3c%0a%3c #foxend 210508-212736-847940#%0a
host:1620509255=71.206.239.38
author:1620443740=CharlieP
diff:1620443740:1620250496:=57,73c57%0a%3c #foxbegin 210508-031541-992410#%0a%3c (:div1 class=expansionhead:)%0a%3c !!!Computer Vision in Hand Tracking for Sign Language %0a%3c -> - CharlieP%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c The current technology of sign language in VR is through tracking of the hands as rigid bodies, that is, that the individual motion of the fingers or arms isn't tracked, only the position and rotation of the hand in space, as well as whether the controller is "gripped" or "open" is tracked. Something that could make sign language in VR much more natural is tracking of the hands and arms using computer vision. This method would track the individual fingers as well as the arms, and possibly the face of the speaker, to better convey more sign language in VR, as well as lower the learning curve for new users. I think that the reason finger tracking in VR isn't more popular is that it's not necessary for playing games, and typically you would be rotating in your room, not just facing one direction. Typically, you don't rotate to various positions when you're having a conversation in real life, so this solution may be viable. %0a%3c %0a%3c Here's a blog post illustrating some of Google's hand recognition technology: %0a%3c https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html%0a%3c %0a%3c Sources: %0a%3c https://towardsdatascience.com/sign-language-recognition-using-deep-learning-6549268c60bd%0a%3c https://paperswithcode.com/task/sign-language-recognition%0a%3c %0a%3c >>%3c%3c%0a%3c #foxend 210508-031541-992410#%0a---%0a> %0a
host:1620443740=74.109.251.161
author:1620250496=MindeeL
diff:1620250496:1620250494:=75,92d74%0a%3c #foxbegin 210505-213456-221890#%0a%3c (:div1 class=messagehead:)%0a%3c >>rfloat%3c%3c   %0a%3c [-05.05.2021 - 14:34-] &nbsp; %0a%3c >>%3c%3c%0a%3c (:if1 authgroup @tas:)%0a%3c >>rfloat%3c%3c%0a%3c {[foxdelrange button 210505-213456-221890 {$FullName} ]}%0a%3c >>%3c%3c%0a%3c (:if1end:)%0a%3c !!!!!MindeeL%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c ''''''%0a%3c >>messageitem%3c%3c%0a%3c This is really cool. I bet it is not only challenging to get the handshapes needed for sign language, but also all the other things that are important to signing such as facial and body movement.  %0a%3c >>%3c%3c%0a%3c #foxend 210505-213456-221890#%0a
host:1620250496=72.95.138.86
author:1620250494=MindeeL
diff:1620250494:1619985863:=75,92d74%0a%3c #foxbegin 210505-213455-76480#%0a%3c (:div1 class=messagehead:)%0a%3c >>rfloat%3c%3c   %0a%3c [-05.05.2021 - 14:34-] &nbsp; %0a%3c >>%3c%3c%0a%3c (:if1 authgroup @tas:)%0a%3c >>rfloat%3c%3c%0a%3c {[foxdelrange button 210505-213455-76480 {$FullName} ]}%0a%3c >>%3c%3c%0a%3c (:if1end:)%0a%3c !!!!!MindeeL%0a%3c (:div1end:) %0a%3c >>messageitem%3c%3c %0a%3c ''''''%0a%3c >>messageitem%3c%3c%0a%3c This is really cool. I bet it is not only challenging to get the handshapes needed for sign language, but also all the other things that are important to signing such as facial and body movement.  %0a%3c >>%3c%3c%0a%3c #foxend 210505-213455-76480#%0a
host:1620250494=72.95.138.86
author:1619985863=kevinx
diff:1619985863:1619985863:=1,79d0%0a%3c (:if authgroup @tas:)%0a%3c %0a%3c (:toggle id=gi show="show grading interface" hide="hide grading interface":)%0a%3c %0a%3c >>id=gi%3c%3c%0a%3c %0a%3c [[GradebookArticles.{$Name}|See article in gradebook]] \\%0a%3c [[{$FullName}?action=diff|See all changes to article]]%0a%3c %0a%3c (:foxform Site.FoxForms#gradeitem:)%0a%3c %0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c >>%3c%3c%0a%3c %0a%3c ----%0a%3c %0a%3c (:ifend:)%0a%3c %0a%3c [[!SignLanguage]]%0a%3c %0a%3c !Sign Language in Virtual Reality%0a%3c %0a%3c :Author: kevinx%0a%3c %0a%3c '''Summary:''' \\%0a%3c %0a%3c [[#summary]]%0a%3c %0a%3c The challenges and benefits of bringing Sign Language to Virtual Reality%0a%3c %0a%3c [[#summaryends]]%0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c For those who sign as their primary language, there has never been a sufficient digital equivalent to the language's expressiveness and sense of presence. Texting, for example, uses written language and does not carry the same raw emotion as sign language. Recently, however, the increased affordability of hand-tracking technology in VR headsets has offered a potential look into the future.%0a%3c %0a%3c Before hand-tracking, deaf and mute users may have had a lot of trouble interpreting spoken language in VR. Many VR social games use virtual avatars whose mouths open and close ambiguously when the user is speaking. Without the ability to accurately lip read or sign, many users felt alienated by VR social games.%0a%3c %0a%3c Recently, in communities such as VRChat, users have been able to program downloadable modifications that make it possible to use hand-tracking controllers to approximate sign language gestures and handshapes. However, the technology is far from mature enough to provide a one-to-one experience equivalent to reality. For example, many hand-tracking technologies only consider whether a finger is "gripped" or "open", not allowing for further subtleties such as if a finger is crossed over another to represent letters such as "P" or "Q" in ASL or whether fingers are partially bent. To compensate, VRChat users have come up with a few VR-specific alternatives for many gestures/handshapes, possibly leading to a new digital sign language. %0a%3c %0a%3c A fully functional sign language suite in VR would have many benefits for the deaf and mute communities: for one, it would provide a space for deaf and mute communities to fully express themselves digitally. The system would replace group video chatting which doesn't provide the same sense of proximity and presence as sign language in real life. Many deaf and mute users who may have felt isolated in their local communities would be able to connect with others across the world in a manner unhindered by technologies which may not have considered them as first priorities. Further, it could contribute to the ability to teach students sign language remotely or gamify sign language education for young learners. %0a%3c %0a%3c There is still much progress to be made in the field of VR sign language, but its development is definitely exciting to follow.%0a%3c %0a%3c Sources:%0a%3c https://uploadvr.com/sign-language-vr-asl/%0a%3c https://www.youtube.com/watch?v=A-vYOlN5qQY%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a%3c ----%0a%3c %0a%3c !!Expansions:%0a%3c [[#expansions]]%0a%3c %0a%3c [[#expansionsend]]%0a%3c %0a%3c ----%0a%3c %25red%25 '''Add an expansion:'''%0a%3c %0a%3c (:if [ exists GradebookExpansions.{$Name}-{$Author} || equal {$Author} {$:Author} ] :)%0a%3c %0a%3c (:else:)%0a%3c %0a%3c (:foxform Site.FoxForms#newexpansion:)%0a%3c %0a%3c (:ifend:)%0a%3c %0a%3c ----%0a%3c ----%0a%3c %0a%3c !!Comments%0a%3c %0a%3c %0a%3c %0a%3c (:section: D:)%0a%3c (:Category: SignLanguage:)%0a\ No newline at end of file%0a
host:1619985863=73.154.247.242
