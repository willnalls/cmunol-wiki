version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36
author=TA_audrey
charset=UTF-8
csum=
ctime=1619847747
host=69.218.234.170
name=GradebookArticles.BetterSpeechSynthesisThroughGANs
rev=3
targets=
text=:Category: LinguisticDiscriminationInTheWild%0a:Essential: {Category.LinguisticDiscriminationInTheWild$:essential}%0a:Title: Better speech synthesis through GANs%0a:Author: rajeev_g%0a:Section: A%0a:Completed: 30.04.2021 - 22:42%0a:Status: needsRevised%0a%0a(:foxform Site.FoxForms#gradeitem:)%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a----%0a%0a%0a%25blue%25 '''Grading History'''%0a%0a[[#history]]%0a#foxbegin 210504-191501-136220#%0a* [-04.05.2021 - 12:15-] || TA_audrey marked as needsRevised%0a#foxend 210504-191501-136220#%0a[[#historyend]]%0a%0a%25blue%25 '''Comments for student'''%0a%0a[[#comments]]%0a#foxbegin 210504-191456-616000#%0a----%0a>>rfloat%3c%3c   %0a[-04.05.2021 - 12:14-] &nbsp; %0a>>%3c%3c%0a!!!!!TA_audrey%0aI don't think this is in the right category %0a(:if1 authgroup @tas:)%0a>>rfloat%3c%3c%0a{[foxdelrange button 210504-191456-616000 {$FullName} ]}%0a>>%3c%3c%0a(:if1end:)%0a#foxend 210504-191456-616000#%0a[[#commentsend]]%0a%0a----%0a----%0a!!%0a%0aSummary: \\%0a%0a[[#summary]]%0a%0aA look into how Generative Adversarial Networks can artificially generate realistic sounding speech.%0a%0a[[#summaryends]]%0a%0a----%0a[[#content]]%0a%0aI'll start with a high-level overview of how the GAN model works. GANs are networks consisting of two neural networks: one that generates fake data (a generator) and one that tries to tell fake data apart from real data (a discriminator). The goal of the generator is to be able to fool the discriminator, and the goal of the discriminator is to be able to tell the difference between fake and real data.%0a%0aIn the training phase, the networks begin playing this game against one another, and learn using a pretty standard model of back-propagation (where weights in the network that contributed to the error are reduced and weights that minimized error are amplified). Depending on the level of fine-tuning, networks can either start with just random weights (in which both parties could be guessing), or they could start with weights pretrained architectures for the types of data they are using.%0a%0aI read a paper recently on the work of one team of researchers in using Generative Adversarial Networks, which you can find here: https://arxiv.org/pdf/1909.11646.pdf.%0a%0aI'll spare you from some of the gritty technical details (although if you are interested in this sort of stuff, the use of Random Window Discriminators [RWDs] as opposed to a single discriminator is really interesting) and stick to the high-level results. By having these networks play this game against one another and learn without really any human input aside from the training data of genuine audio, the researchers efficiently generated a network that was evaluated as sounding pretty natural by humans.%0a%0aIt's interesting to see how much progress Machine Learning can make in spaces like speech generation, which (as per what I've read, but I'm no expert), traditional approaches face a lot of difficulty.%0a%0a[[#contentends]]%0a----%0a(:GradedBy: TA_audrey:)
time=1620155700
author:1620155700=TA_audrey
diff:1620155700:1620155696:=7,8c7,8%0a%3c :Status: needsRevised%0a%3c %0a---%0a> :Status: ungraded%0a> %0a18,20c18%0a%3c #foxbegin 210504-191501-136220#%0a%3c * [-04.05.2021 - 12:15-] || TA_audrey marked as needsRevised%0a%3c #foxend 210504-191501-136220#%0a---%0a> %0a67,68c65%0a%3c ----%0a%3c (:GradedBy: TA_audrey:)%0a\ No newline at end of file%0a---%0a> ----%0a\ No newline at end of file%0a
host:1620155700=69.218.234.170
author:1620155696=TA_audrey
diff:1620155696:1619847747:=24,36c24%0a%3c #foxbegin 210504-191456-616000#%0a%3c ----%0a%3c >>rfloat%3c%3c   %0a%3c [-04.05.2021 - 12:14-] &nbsp; %0a%3c >>%3c%3c%0a%3c !!!!!TA_audrey%0a%3c I don't think this is in the right category %0a%3c (:if1 authgroup @tas:)%0a%3c >>rfloat%3c%3c%0a%3c {[foxdelrange button 210504-191456-616000 {$FullName} ]}%0a%3c >>%3c%3c%0a%3c (:if1end:)%0a%3c #foxend 210504-191456-616000#%0a---%0a> %0a
host:1620155696=69.218.234.170
author:1619847747=rajeev_g
diff:1619847747:1619847747:=1,53d0%0a%3c :Category: LinguisticDiscriminationInTheWild%0a%3c :Essential: {Category.LinguisticDiscriminationInTheWild$:essential}%0a%3c :Title: Better speech synthesis through GANs%0a%3c :Author: rajeev_g%0a%3c :Section: A%0a%3c :Completed: 30.04.2021 - 22:42%0a%3c :Status: ungraded%0a%3c %0a%3c (:foxform Site.FoxForms#gradeitem:)%0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c ----%0a%3c %0a%3c %0a%3c %25blue%25 '''Grading History'''%0a%3c %0a%3c [[#history]]%0a%3c %0a%3c [[#historyend]]%0a%3c %0a%3c %25blue%25 '''Comments for student'''%0a%3c %0a%3c [[#comments]]%0a%3c %0a%3c [[#commentsend]]%0a%3c %0a%3c ----%0a%3c ----%0a%3c !!%0a%3c %0a%3c Summary: \\%0a%3c %0a%3c [[#summary]]%0a%3c %0a%3c A look into how Generative Adversarial Networks can artificially generate realistic sounding speech.%0a%3c %0a%3c [[#summaryends]]%0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c I'll start with a high-level overview of how the GAN model works. GANs are networks consisting of two neural networks: one that generates fake data (a generator) and one that tries to tell fake data apart from real data (a discriminator). The goal of the generator is to be able to fool the discriminator, and the goal of the discriminator is to be able to tell the difference between fake and real data.%0a%3c %0a%3c In the training phase, the networks begin playing this game against one another, and learn using a pretty standard model of back-propagation (where weights in the network that contributed to the error are reduced and weights that minimized error are amplified). Depending on the level of fine-tuning, networks can either start with just random weights (in which both parties could be guessing), or they could start with weights pretrained architectures for the types of data they are using.%0a%3c %0a%3c I read a paper recently on the work of one team of researchers in using Generative Adversarial Networks, which you can find here: https://arxiv.org/pdf/1909.11646.pdf.%0a%3c %0a%3c I'll spare you from some of the gritty technical details (although if you are interested in this sort of stuff, the use of Random Window Discriminators [RWDs] as opposed to a single discriminator is really interesting) and stick to the high-level results. By having these networks play this game against one another and learn without really any human input aside from the training data of genuine audio, the researchers efficiently generated a network that was evaluated as sounding pretty natural by humans.%0a%3c %0a%3c It's interesting to see how much progress Machine Learning can make in spaces like speech generation, which (as per what I've read, but I'm no expert), traditional approaches face a lot of difficulty.%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a\ No newline at end of file%0a
host:1619847747=73.154.247.188
