version=pmwiki-2.2.130 ordered=1 urlencoded=1
agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36
author=TA_lili
charset=UTF-8
csum=
ctime=1620157545
host=74.111.97.246
name=GradebookExpansions.DiscriminationOfAAVEInSocialMediaFilteringTechnology-jjmonroe
rev=2
targets=Articles.DiscriminationOfAAVEInSocialMediaFilteringTechnology,Profiles.ZoeC
text=:Category: LinguisticDiscriminationInTheWild%0a:Expansion: An alternative perspective with regard to machine learning%0a:Author: jjmonroe%0a:Original: [[Articles.DiscriminationOfAAVEInSocialMediaFilteringTechnology|DiscriminationOfAAVEInSocialMediaFilteringTechnology]] %0a:OriginalAuthor: [[Profiles.ZoeC|ZoeC]]%0a:Section: C%0a:Completed: 04.05.2021 - 12:45%0a:Status: complete%0a%0a(:foxform Site.FoxForms#gradeExpansion:)%0a(:foxform Site.FoxForms#gradingcomment:)%0a%0a%0a%25red%25 '''Grading History'''%0a%0a[[#history]]%0a#foxbegin 210505-022208-437640#%0a* [-04.05.2021 - 19:22-] || TA_lili marked as complete%0a#foxend 210505-022208-437640#%0a[[#historyend]]%0a%0a%25red%25 '''Comments to student'''%0a%0a[[#comments]]%0a%0a[[#commentsend]]%0a%0a----%0a----%0a!!%0a%0a%0a----%0a[[#content]]%0a%0aDue to the nature of the technology which is being used here, the implied intentionality may be more coincidental. Machine learning algorithms aren't necessarily "programmed" the same way a traditional piece of software is; they are fed a set of data and build a model to predict whether future items match that data. If a machine learning algorithm that was created to distinguish flowers from leaves was later found to do a poor job of labeling a certain type of flower it had little experience dealing with, it wouldn't be the the programmers explicitly discriminating against that type, but a failing of the algorithm. Likewise, it seems wrong to say that 'dope ass' was flagged BECAUSE it was AAVE. Assuming that this was a conscious choice rather than an emergent property of the fact that the dataset the model was trained on (an archive of wikipedia comments) didn't contain much AAVE and the algorithm just didn't know what to do with it. Although the legacy of discrimination in tech goes far back, it seems possible in this case that it may be an unintentional side effect of narrow sampling rather than deliberate exclusion.%0a%0a[[#contentends]]%0a----%0a(:Category:)%0a(:GradedBy: TA_lili:)
time=1620181327
author:1620181327=TA_lili
diff:1620181327:1620157545:=8,9c8,9%0a%3c :Status: complete%0a%3c %0a---%0a> :Status: ungraded%0a> %0a17,19c17%0a%3c #foxbegin 210505-022208-437640#%0a%3c * [-04.05.2021 - 19:22-] || TA_lili marked as complete%0a%3c #foxend 210505-022208-437640#%0a---%0a> %0a40,41c38%0a%3c (:Category:)%0a%3c (:GradedBy: TA_lili:)%0a\ No newline at end of file%0a---%0a> (:Category:)%0a\ No newline at end of file%0a
host:1620181327=74.111.97.246
author:1620157545=jjmonroe
diff:1620157545:1620157545:=1,38d0%0a%3c :Category: LinguisticDiscriminationInTheWild%0a%3c :Expansion: An alternative perspective with regard to machine learning%0a%3c :Author: jjmonroe%0a%3c :Original: [[Articles.DiscriminationOfAAVEInSocialMediaFilteringTechnology|DiscriminationOfAAVEInSocialMediaFilteringTechnology]] %0a%3c :OriginalAuthor: [[Profiles.ZoeC|ZoeC]]%0a%3c :Section: C%0a%3c :Completed: 04.05.2021 - 12:45%0a%3c :Status: ungraded%0a%3c %0a%3c (:foxform Site.FoxForms#gradeExpansion:)%0a%3c (:foxform Site.FoxForms#gradingcomment:)%0a%3c %0a%3c %0a%3c %25red%25 '''Grading History'''%0a%3c %0a%3c [[#history]]%0a%3c %0a%3c [[#historyend]]%0a%3c %0a%3c %25red%25 '''Comments to student'''%0a%3c %0a%3c [[#comments]]%0a%3c %0a%3c [[#commentsend]]%0a%3c %0a%3c ----%0a%3c ----%0a%3c !!%0a%3c %0a%3c %0a%3c ----%0a%3c [[#content]]%0a%3c %0a%3c Due to the nature of the technology which is being used here, the implied intentionality may be more coincidental. Machine learning algorithms aren't necessarily "programmed" the same way a traditional piece of software is; they are fed a set of data and build a model to predict whether future items match that data. If a machine learning algorithm that was created to distinguish flowers from leaves was later found to do a poor job of labeling a certain type of flower it had little experience dealing with, it wouldn't be the the programmers explicitly discriminating against that type, but a failing of the algorithm. Likewise, it seems wrong to say that 'dope ass' was flagged BECAUSE it was AAVE. Assuming that this was a conscious choice rather than an emergent property of the fact that the dataset the model was trained on (an archive of wikipedia comments) didn't contain much AAVE and the algorithm just didn't know what to do with it. Although the legacy of discrimination in tech goes far back, it seems possible in this case that it may be an unintentional side effect of narrow sampling rather than deliberate exclusion.%0a%3c %0a%3c [[#contentends]]%0a%3c ----%0a%3c (:Category:)%0a\ No newline at end of file%0a
host:1620157545=73.174.7.241
